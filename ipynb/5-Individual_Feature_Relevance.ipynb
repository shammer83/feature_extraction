{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import numpy as np\n",
    "from scipy import stats as st\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_diabetes\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Feature Relevane with ... Linear Models\n",
    "\n",
    "- $n$, the number of instances, rows\n",
    "- $p$, the number of features, columns\n",
    "\n",
    "### The Model\n",
    "\n",
    "$$y=\\beta_0+\\beta_1x_1+\\dots+\\beta_px_p$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Mean\n",
    "\n",
    "$$\\mu = \\text{E}[y]=\\frac1n\\sum y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Variance\n",
    "\n",
    "How far off will a measurement be from the mean?\n",
    "\n",
    "$$\\text{Var}(y)=\\text{E}\\left[(y-\\mu)^2\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSS, the Total Sum of Squares\n",
    "TSS measures the total variance in $y$ i.e. the variance  before the regression is performed.\n",
    "\n",
    "$$\\text{TSS}=\\sum (y_i-\\mu)^2= nVar(y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSS, the Residual Sum of Squares\n",
    "\n",
    "RSS measures the variance left unexplained after performing the regression. \n",
    "\n",
    "$$\\text{RSS}=\\sum (y_i-\\hat f(x_i))^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$, the Coefficient of Determination\n",
    "\n",
    "$$R^2=\\frac{\\text{TSS}-\\text{RSS}}{\\text{TSS}} = 1 - \\frac{RSS}{TSS} $$\n",
    "\n",
    "TSS âˆ’ RSS measures the amount of variability in the response that is explained by performing the regression\n",
    "\n",
    "$R^2$ measures the proportion of variance in $y$ that can be explained using $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test statistic is a statistic (a quantity derived from the sample) used in statistical hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hypothesis test is typically specified in terms of a test statistic, considered as a numerical summary of a data-set that reduces the data to one value that can be used to perform the hypothesis test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, a test statistic is selected or defined in such a way as to quantify, within observed data, behaviours that would distinguish the null from the alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Statistic\n",
    "\n",
    "$$F \\approx \\frac{TSS-RSS}{RSS} = \\frac{\\text{explained variance}}{\\text{unexplained variance}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Relevance\n",
    "1. Is at least one of the predictors $x_1 , x_2 , \\dots , x_p$ useful in predicting the response?\n",
    "2. Do all the predictors help to explain $y$, or is only a subset of the predictors useful?\n",
    "3. How well does the model fit the data?\n",
    "4. Given a set of predictor values, what response value should we predict, and how accurate is our prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One: Is There a Relationship Between the Response and Predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_diab = ['Age','Sex','Body_mass_index','Average_blood_pressure','S1','S2','S3','S4','S5','S6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    ==============      ==================\n",
    "    Samples total       442\n",
    "    Dimensionality      10\n",
    "    Features            real, -.2 < x < .2\n",
    "    Targets             integer 25 - 346\n",
    "    ==============      =================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_diab, y_diab = load_diabetes(return_X_y=True)\n",
    "X_diab = pd.DataFrame(X_diab, columns=cols_diab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_diab.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data_diab = pd.merge(X_diab, pd.DataFrame(y_diab), left_index=True, right_index=True)\n",
    "full_data_diab.columns = list(X_diab.columns) + ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(full_data_diab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sample and an apparent effect, what is the probability of seeing such an effect by chance?\n",
    "\n",
    "1. Choose a **test statistic**\n",
    "1. Define a **null hypothesis**\n",
    "1. Compute a **p-value**\n",
    "1. Interpret the result:\n",
    "\n",
    "If the p-value is low, the effect is said to be **statistically significant**, which means that it is unlikely to have occurred by chance. \n",
    "\n",
    "1. test stat: t-statistic of a feature\n",
    "2. **H**$_0$: the feature is not important in predicting the target\n",
    "3. Compute p-values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Simple Linear Regression, our Test Statistic is typically the $t$-statistic\n",
    "\n",
    "$$t_{\\widehat{\\beta}} = \\frac{\\widehat\\beta - \\beta_0}{\\mathrm{s.e.}(\\widehat\\beta)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R notation:\n",
    "\n",
    "    \"target ~ Body_mass_index\"\n",
    "    \n",
    "`target` can be predicted by `Body_mass_index`.\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x_1$$\n",
    "\n",
    "where $y$ is the target and $x_1$ is the `Body_mass_index`.\n",
    "\n",
    "$$\\text{H}_0: \\beta_0 = \\beta_1=0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ols(\"target ~ Body_mass_index\", full_data_diab).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can we reject the null hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Linear Regression against all Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regress one at a time.\n",
    "for feat in cols_diab:\n",
    "    model = ols(\"target ~ {}\".format(feat), full_data_diab).fit()\n",
    "    print(\"{:25} {}\".format(feat, model.pvalues[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#'+'.join()...joins on all _\n",
    "model = ols(\"target ~ \" + \"+\".join(cols_diab), full_data_diab).fit()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#note... p values change if you regress individually or regress on features combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two: Deciding on Important Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    =================   ==============\n",
    "    Classes                          3\n",
    "    Samples per class               50\n",
    "    Samples total                  150\n",
    "    Dimensionality                   4\n",
    "    Features            real, positive\n",
    "    =================   =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris_cols = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "full_data_iris = pd.merge(\n",
    "                pd.DataFrame(iris.data, \n",
    "                             columns=iris_cols),\n",
    "                pd.DataFrame(iris.target,\n",
    "                             columns=['species']),\n",
    "                left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_iris.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(\"species ~ sepal_width + sepal_length\", full_data_iris).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(\"species ~ sepal_width + sepal_length + petal_length + petal_width\", full_data_iris).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(\"species ~ sepal_length + petal_length + petal_width - 1\", full_data_iris).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,6))\n",
    "for i, feat in enumerate(['sepal_length', 'sepal_width', 'petal_length', 'petal_width']):\n",
    "    fig.add_subplot(1,4,i+1)\n",
    "    sns.boxplot('species', feat, data=full_data_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Way Anova\n",
    "\n",
    "Use one-way anova when you have one nominal variable and one measurement variable; the nominal variable divides the measurements into two or more groups. It tests whether the means of the measurement variable are the same for the different groups.\n",
    "\n",
    "#### Null hypothesis\n",
    "The statistical null hypothesis is that the means of the measurement variable are the same for the different categories of data; the alternative hypothesis is that they are not all the same. \n",
    "\n",
    "$$H_0:\\mu_1=\\mu_2=\\dots=\\mu_p$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "species_groups = full_data_iris.groupby('species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups.agg(['var', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = f_oneway(full_data_iris[full_data_iris['species']==0].drop('species', axis=1),\n",
    "                   full_data_iris[full_data_iris['species']==1].drop('species', axis=1),\n",
    "                   full_data_iris[full_data_iris['species']==2].drop('species', axis=1))\n",
    "list(zip(iris_cols, results.pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E = np.random.uniform(0, 0.1, size=(len(iris.data), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.hstack((iris.data, E))\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_indices = np.arange(X.shape[-1])\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "selector.fit(X, y)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "scores /= scores.max()\n",
    "plt.bar(X_indices - .45, scores, width=.2,\n",
    "        label=r'Univariate score ($-Log(p_{value})$)', color='darkorange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X, y)\n",
    "\n",
    "svm_weights = (clf.coef_ ** 2).sum(axis=0)\n",
    "svm_weights /= svm_weights.max()\n",
    "\n",
    "plt.bar(X_indices - .25, svm_weights, width=.2, label='SVM weight',\n",
    "        color='navy')\n",
    "\n",
    "clf_selected = svm.SVC(kernel='linear')\n",
    "clf_selected.fit(selector.transform(X), y)\n",
    "\n",
    "svm_weights_selected = (clf_selected.coef_ ** 2).sum(axis=0)\n",
    "svm_weights_selected /= svm_weights_selected.max()\n",
    "\n",
    "plt.bar(X_indices[selector.get_support()] - .05, svm_weights_selected,\n",
    "        width=.2, label='SVM weights after selection', color='c')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
